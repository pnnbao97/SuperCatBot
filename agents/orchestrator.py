from pydantic import BaseModel, Field
from typing import Literal, TypedDict, Annotated
from operator import add

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import InMemorySaver
from agents.chatbot import chatbot_node
from agents.video_agent import video_agent_node
from agents.memory import State
from agents.models import main_llm

import logging

logger = logging.getLogger(__name__)

# ==========================
# AGENT MAPPING
# ==========================
agent_nodes = {
    "chatbot": chatbot_node,
    "video_agent": video_agent_node
}

# ==========================
# ROUTING SCHEMA
# ==========================
class RouteSchema(BaseModel):
    next: Literal["chatbot", "video_agent"]
    instructions: str = Field(
        description="HÆ°á»›ng dáº«n cá»¥ thá»ƒ cho agent tiáº¿p theo"
    )

memory = InMemorySaver()
main_llm_with_routing = main_llm.with_structured_output(RouteSchema)

# ==========================
# ORCHESTRATOR NODE
# ==========================
async def orchestrator_node(state: State):
    """Nháº¡c trÆ°á»Ÿng Ä‘iá»u phá»‘i"""
    
    messages = state["messages"]
    
    # Kiá»ƒm tra xem cÃ³ agent nÃ o vá»«a tráº£ lá»i khÃ´ng
    last_message = messages[-1] if messages else None
    has_agent_response = (
        isinstance(last_message, AIMessage) and 
        len(messages) > 1  # CÃ³ cáº£ user message
    )
    
    system_prompt = SystemMessage(
        content=(
            f"Báº¡n lÃ  supervisor Ä‘iá»u phá»‘i team agents.\n\n"
            f"Agents cÃ³ sáºµn: {list(agent_nodes.keys())}\n\n"
            f"Chá»©c nÄƒng:\n"
            f"- chatbot: Chat thÃ´ng thÆ°á»ng, há»i Ä‘Ã¡p chung, tÆ° váº¥n\n"
            f"- video_agent: PhÃ¢n tÃ­ch video, xá»­ lÃ½ video\n\n"
            f"Tráº£ vá»:\n"
            f"- next: tÃªn agent\n"
            f"- instructions: hÆ°á»›ng dáº«n cá»¥ thá»ƒ cho agent"
        )
    )
    
    response = await main_llm_with_routing.ainvoke([system_prompt] + messages)
    
    logger.info(f"ğŸ¯ Orchestrator decision: {response.next}")
    logger.info(f"ğŸ“ Instructions: {response.instructions}")
    
    return {
        "next_agent": response.next,
        "agent_instructions": response.instructions
    }


# ==========================
# ROUTING FUNCTION
# ==========================
def route_to_agent(state: State) -> str:
    """Conditional routing dá»±a trÃªn orchestrator decision"""
    next_agent = state.get("next_agent", "chatbot")
    logger.info(f"â¡ï¸  Routing to: {next_agent}")
    return next_agent


# ==========================
# GRAPH SETUP
# ==========================
graph_builder = StateGraph(State)

# Add orchestrator
graph_builder.add_node("orchestrator", orchestrator_node)

# Add agents vÃ  edge quay vá» orchestrator
for agent_name, node_func in agent_nodes.items():
    graph_builder.add_node(agent_name, node_func)
    # graph_builder.add_edge(agent_name, "orchestrator")

# Entry point
graph_builder.set_entry_point("orchestrator")

# Conditional routing tá»« orchestrator
graph_builder.add_conditional_edges(
    "orchestrator",
    route_to_agent,
    {
        "chatbot": "chatbot",
        "video_agent": "video_agent",
    }
)

# Compile vá»›i memory
graph = graph_builder.compile(checkpointer=memory)


# ==========================
# ORCHESTRATION AGENT
# ==========================
class OrchestratorAgent:
    """Main orchestrator agent Ä‘á»ƒ interact vá»›i graph"""

    def __init__(self, thread_id: str):
        self.graph = graph
        self.config = {"configurable": {"thread_id": thread_id}}

    async def generate_answer(self, message: str) -> str:
        """Generate answer tá»« user message"""
        try:
            # Initial state
            initial_state = {
                "messages": [HumanMessage(content=message)]
            }
            
            # Invoke graph
            result = await self.graph.ainvoke(initial_state, self.config)
            
            # Extract final response
            messages = result.get("messages", [])
            if not messages:
                return "âŒ KhÃ´ng cÃ³ response tá»« agent"
            
            # TÃ¬m AIMessage cuá»‘i cÃ¹ng (response tá»« agent)
            for msg in reversed(messages):
                if isinstance(msg, AIMessage):
                    return msg.content
            
            return "âŒ KhÃ´ng tÃ¬m tháº¥y AI response"
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i orchestrator: {e}", exc_info=True)
            return f"âŒ ÄÃ£ xáº£y ra lá»—i: {str(e)}"
    
    async def stream_answer(self, message: str):
        """Stream answer vá»›i progress updates"""
        try:
            initial_state = {
                "messages": [HumanMessage(content=message)]
            }
            
            async for event in self.graph.astream(initial_state, self.config):
                logger.info(f"ğŸ“¦ Event: {event}")
                yield event
                
        except Exception as e:
            logger.error(f"âŒ Lá»—i stream: {e}", exc_info=True)
            yield {"error": str(e)}