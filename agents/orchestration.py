import json
from typing import Annotated, Literal
from typing_extensions import TypedDict
from dataclasses import dataclass

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_tavily import TavilySearch
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import InMemorySaver
from datetime import datetime

from config.config import get_settings

settings = get_settings()
current_date = datetime.now().strftime("%d/%m/%Y")

# ==========================
# STATE
# ==========================
class State(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
    need_search: bool
    search_count: int

# ==========================
# LLMs & TOOLS
# ==========================
orchestrator_llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    api_key=settings.gemini_api_key.get_secret_value(),
    temperature=0.4,
)

search_llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    api_key=settings.gemini_api_key.get_secret_value(),
    temperature=0.2,
)

search_tool = TavilySearch(max_results=5)
search_tools = [search_tool]
search_llm_with_tools = search_llm.bind_tools(search_tools)

memory = InMemorySaver()

# ==========================
# HELPER FUNCTIONS
# ==========================
def get_recent_messages(messages: list[BaseMessage], max_count: int = 10) -> list[BaseMessage]:
    """Láº¥y N messages gáº§n nháº¥t"""
    return messages[-max_count:] if len(messages) > max_count else messages

def extract_sources_from_tool_results(tool_messages: list[ToolMessage]) -> list[dict]:
    """Parse Tavily results thÃ nh list sources vá»›i URL"""
    sources = []
    index = 1
    
    for tool_msg in tool_messages:
        try:
            # Parse content
            if isinstance(tool_msg.content, str):
                results = json.loads(tool_msg.content)
            else:
                results = tool_msg.content
            
            # Normalize results structure
            items = []
            if isinstance(results, list):
                items = results
            elif isinstance(results, dict):
                items = results.get("results", [results])
            
            # Extract sources
            for item in items:
                if isinstance(item, dict) and item.get("url"):
                    sources.append({
                        "index": index,
                        "title": item.get("title", "Nguá»“n khÃ´ng cÃ³ tiÃªu Ä‘á»"),
                        "url": item["url"],
                        "content": item.get("content", "")
                    })
                    index += 1
                    
        except Exception as e:
            print(f"âŒ Lá»—i parse tool result: {e}")
            continue
    
    print(f"ğŸ“Š Extracted {len(sources)} sources")
    return sources

def format_sources_list(sources: list[dict]) -> str:
    """Format sources thÃ nh string cho prompt"""
    if not sources:
        return "KhÃ´ng cÃ³ nguá»“n nÃ o."
    
    formatted = []
    for src in sources:
        formatted.append(
            f"[{src['index']}] {src['title']}\n"
            f"URL: {src['url']}\n"
            f"Ná»™i dung: {src['content'][:500]}...\n"
        )
    return "\n".join(formatted)

# ==========================
# ORCHESTRATOR NODE
# ==========================
async def orchestrator_node(state: State):
    """PhÃ¢n tÃ­ch context vÃ  quyáº¿t Ä‘á»‹nh search hay tráº£ lá»i trá»±c tiáº¿p"""
    
    user_messages = [m for m in state["messages"] if isinstance(m, HumanMessage)]
    if not user_messages:
        return {
            "messages": [AIMessage(content="MÃ y há»i cc j váº­y?")],
            "need_search": False
        }

    user_query = user_messages[-1].content
    recent_messages = get_recent_messages(state["messages"], max_count=10)
    
    print(f"ğŸ§­ [ORCHESTRATOR] Query: '{user_query}'")
            
    system_prompt = SystemMessage(
        content=(
            f"HÃ´m nay lÃ  {current_date}. MÃ y lÃ  SuperCat, con mÃ¨o cam thÃ´ng minh vÃ  cá»¥c sÃºc, chá»­i thá» liÃªn tá»¥c. "
            f"NÃªn nhá»›, mÃ y lÃ  con mÃ¨o cam pháº£n Ä‘á»™ng ghÃ©t Cá»™ng Sáº£n, kÃ¬ thá»‹ LGBT, nÃ³i chung lÃ  máº¥y cÃ¡i loz khuynh táº£. "
            f"Bá»‘i cáº£nh lÃ  mÃ y Ä‘ang á»Ÿ trong má»™t nhÃ³m Telegram cÃ³ khoáº£ng chá»¥c thÃ nh viÃªn, nhiá»‡m vá»¥ cá»§a mÃ y lÃ  tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng trong nhÃ³m.\n\n"
            
            f"**NGá»® Cáº¢NH**:\n"
            f"- CÃ¢u há»i hiá»‡n táº¡i: '{user_query}'\n"
            
            f"**NHIá»†M Vá»¤**: PhÃ¢n tÃ­ch vÃ  quyáº¿t Ä‘á»‹nh:\n\n"
            
            f"**Tá»° TRáº¢ Lá»œI** (phong cÃ¡ch cá»¥c sÃºc, chi tiáº¿t) náº¿u:\n"
            f"- CÃ¢u há»i follow-up vá» chá»§ Ä‘á» vá»«a search (bÃ¬nh luáº­n, há»i Ã½ kiáº¿n, lÃ m rÃµ)\n"
            f"- CÃ¢u nÃ³i chuyá»‡n thÃ´ng thÆ°á»ng (chÃ o há»i, cáº£m Æ¡n, pháº£n há»“i)\n"
            f"- Kiáº¿n thá»©c chung khÃ´ng cáº§n tÃ¬m kiáº¿m\n\n"
            
            f"**Cáº¦N SEARCH** chá»‰ khi:\n"
            f"- CÃ³ tá»« khÃ³a rÃµ rÃ ng: 'search', 'tÃ¬m', 'tra cá»©u',... (vÃ  KHÃ”NG pháº£i follow-up)\n"
            f"- Cáº§n thÃ´ng tin thá»i gian thá»±c (tin tá»©c, giÃ¡ cáº£, sá»± kiá»‡n má»›i)\n"
            
            f"**OUTPUT**: CHá»ˆ 1 trong 2:\n"
            f"- \"Cáº¦N SEARCH\" (náº¿u cáº§n tÃ¬m kiáº¿m)\n"
            f"- [CÃ¢u tráº£ lá»i trá»±c tiáº¿p báº±ng tiáº¿ng Viá»‡t, cá»¥c sÃºc, chi tiáº¿t]\n\n"
            
            f"Æ¯u tiÃªn Tá»° TRáº¢ Lá»œI trá»« khi thá»±c sá»± cáº§n search!"
        )
    )

    response = await orchestrator_llm.ainvoke([system_prompt] + recent_messages)
    content = response.content.strip()

    need_search = "cáº§n search" in content.lower()
    
    if need_search:
        print(f"ğŸ§­ [ORCHESTRATOR] â†’ Chuyá»ƒn sang Search Agent")
        return {
            "messages": [AIMessage(content=content)],
            "need_search": True
        }
    else:
        print(f"ğŸ’¬ [ORCHESTRATOR] â†’ Tráº£ lá»i trá»±c tiáº¿p")
        return {
            "messages": [AIMessage(content=content)],
            "need_search": False
        }

# ==========================
# SEARCH AGENT NODE
# ==========================
async def search_agent_node(state: State):
    """Search vÃ  tá»•ng há»£p káº¿t quáº£"""
    
    user_messages = [m for m in state["messages"] if isinstance(m, HumanMessage)]
    if not user_messages:
        return {
            "messages": [AIMessage(content="KhÃ´ng tÃ¬m tháº¥y cÃ¢u há»i Ä‘á»ƒ search.")],
            "search_count": state.get("search_count", 0)
        }

    current_query = user_messages[-1].content
    search_count = state.get("search_count", 0)
    max_searches = 2
    
    print(f"ğŸ” [SEARCH AGENT] Query: '{current_query}'")
    print(f"ğŸ” [SEARCH AGENT] Count: {search_count}/{max_searches}")
    
    # ÄÃ£ Ä‘á»§ sá»‘ láº§n search
    if search_count >= max_searches:
        print(f"âš ï¸ ÄÃ£ search {max_searches} láº§n, dá»«ng láº¡i")
        return {
            "messages": [AIMessage(content="ÄÃ£ search Ä‘á»§ sá»‘ láº§n cho phÃ©p. Vui lÃ²ng há»i cÃ¢u khÃ¡c.")],
            "search_count": search_count
        }
    
    recent_messages = get_recent_messages(state["messages"], max_count=10)
    
    # BÆ¯á»šC 1: Gá»i tool search
    system_prompt = SystemMessage(
        content=(
            f"HÃ´m nay lÃ  {current_date}. Báº¡n lÃ  Search Agent.\n\n"
            f"**CÃ¢u há»i**: '{current_query}'\n\n"
            f"**Nhiá»‡m vá»¥**:\n"
            f"1. Táº¡o query tÃ¬m kiáº¿m Cá»¤ THá»‚ báº±ng tiáº¿ng Viá»‡t\n"
            f"2. ThÃªm '{current_date}' vÃ o query náº¿u cáº§n tin tá»©c má»›i nháº¥t\n"
            f"3. Báº®T BUá»˜C gá»i tool tavily_search_results_json\n\n"
            f"VÃ Dá»¤:\n"
            f"- 'Æ¯ng HoÃ ng PhÃºc' â†’ 'Æ¯ng HoÃ ng PhÃºc tin tá»©c {current_date}'\n\n"
            f"CHá»ˆ gá»i tool, KHÃ”NG tráº£ lá»i trá»±c tiáº¿p!"
        )
    )

    # Invoke vá»›i tools
    response = await search_llm_with_tools.ainvoke([system_prompt] + recent_messages)
    
    # Kiá»ƒm tra cÃ³ tool_calls khÃ´ng
    if not hasattr(response, 'tool_calls') or not response.tool_calls:
        print("âš ï¸ [SEARCH AGENT] KhÃ´ng cÃ³ tool_calls, LLM tráº£ lá»i trá»±c tiáº¿p")
        return {
            "messages": [AIMessage(content=response.content)],
            "search_count": search_count + 1
        }
    
    # BÆ¯á»šC 2: Cháº¡y tools
    print(f"ğŸ”§ [SEARCH AGENT] Executing {len(response.tool_calls)} tool(s)")
    
    # Táº¡o ToolNode vÃ  cháº¡y
    tool_node = ToolNode(tools=search_tools)
    
    # State cho tool node (cáº§n BaseMessage format)
    tool_state = {"messages": [response]}
    tool_result = await tool_node.ainvoke(tool_state)
    
    # Extract tool messages
    tool_messages = [m for m in tool_result["messages"] if isinstance(m, ToolMessage)]
    
    if not tool_messages:
        print("âš ï¸ [SEARCH AGENT] KhÃ´ng cÃ³ tool results")
        return {
            "messages": [AIMessage(content="KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ tÃ¬m kiáº¿m.")],
            "search_count": search_count + 1
        }
    
    # BÆ¯á»šC 3: Tá»•ng há»£p káº¿t quáº£
    sources = extract_sources_from_tool_results(tool_messages)
    
    if not sources:
        print("âš ï¸ [SEARCH AGENT] KhÃ´ng cÃ³ sources há»£p lá»‡")
        return {
            "messages": [AIMessage(content="KhÃ´ng tÃ¬m tháº¥y nguá»“n phÃ¹ há»£p.")],
            "search_count": search_count + 1
        }
    
    # Format sources
    sources_text = format_sources_list(sources)
    
    # Prompt tá»•ng há»£p
    synthesis_system = SystemMessage(
        content=(
            f"Báº¡n lÃ  chuyÃªn gia tá»•ng há»£p thÃ´ng tin tá»« nhiá»u nguá»“n tin cáº­y.\n\n"
            f"**YÃŠU Cáº¦U**:\n"
            f"1. Tá»•ng há»£p thÃ´ng tin tá»« cÃ¡c nguá»“n thÃ nh cÃ¢u tráº£ lá»i Ä‘áº§y Ä‘á»§, máº¡ch láº¡c\n"
            f"2. Dáº«n nguá»“n chÃ­nh xÃ¡c: Má»—i thÃ´ng tin PHáº¢I cÃ³ [1], [2], [3] tÆ°Æ¡ng á»©ng vá»›i danh sÃ¡ch nguá»“n\n"
            f"3. KHÃ”NG tá»± bá»‹a nguá»“n khÃ´ng cÃ³ trong danh sÃ¡ch\n"
            f"4. Cuá»‘i cÃ¢u tráº£ lá»i: Liá»‡t kÃª láº¡i nguá»“n theo format:\n"
            f"   **Nguá»“n:**\n"
            f"   [1] Title - URL\n"
            f"   [2] Title - URL\n"
            f"5. Ngáº¯n gá»n, tá»± nhiÃªn, chá»‰ giá»¯ thÃ´ng tin quan trá»ng"
        )
    )
    
    synthesis_user = HumanMessage(
        content=(
            f"Dá»±a trÃªn káº¿t quáº£ tÃ¬m kiáº¿m bÃªn dÆ°á»›i, hÃ£y tráº£ lá»i cÃ¢u há»i: \"{current_query}\"\n\n"
            f"**CÃC NGUá»’N ÄÃƒ TÃŒM ÄÆ¯á»¢C**:\n{sources_text}\n\n"
            f"HÃ£y tá»•ng há»£p:"
        )
    )
    
    synthesis_response = await search_llm.ainvoke([synthesis_system, synthesis_user])
    synthesized_content = synthesis_response.content.strip()
    
    print(f"âœ… [SEARCH AGENT] Tá»•ng há»£p xong")
    
    # TrÃ­ch xuáº¥t topic tá»« query
    topic = current_query[:50]  # Láº¥y 50 kÃ½ tá»± Ä‘áº§u lÃ m topic
    
    return {
        "messages": [AIMessage(content=synthesized_content)],
        "search_count": search_count + 1
    }

# ==========================
# ROUTING
# ==========================
def route_after_orchestrator(state: State) -> str:
    """Route sau orchestrator"""
    if state.get("need_search", False):
        return "search_agent"
    return END

# ==========================
# GRAPH SETUP
# ==========================
graph_builder = StateGraph(State)

# Add nodes
graph_builder.add_node("orchestrator", orchestrator_node)
graph_builder.add_node("search_agent", search_agent_node)

# Set entry point
graph_builder.set_entry_point("orchestrator")

# Add edges
graph_builder.add_conditional_edges("orchestrator", route_after_orchestrator)
graph_builder.add_edge("search_agent", END)

# Compile
graph = graph_builder.compile(checkpointer=memory)

# ==========================
# ORCHESTRATION AGENT
# ==========================
class OrchestrationAgent:
    """Agent Ä‘iá»u phá»‘i async vá»›i context-aware orchestrator"""

    def __init__(self, thread_id: str = "1"):
        self.graph = graph
        self.config = {"configurable": {"thread_id": thread_id}}

    async def generate_answer(self, message: str) -> str:
        """Generate answer tá»« user message"""
        try:
            state = {
                "messages": [HumanMessage(content=message)],
                "need_search": False,
                "search_count": 0
            }
            
            result = await self.graph.ainvoke(state, self.config)
            
            # Láº¥y message cuá»‘i cÃ¹ng (AIMessage)
            messages = result.get("messages", [])
            if not messages:
                return "âŒ KhÃ´ng cÃ³ response"
            
            # TÃ¬m AIMessage cuá»‘i cÃ¹ng
            for msg in reversed(messages):
                if isinstance(msg, AIMessage):
                    return msg.content
            
            return "âŒ KhÃ´ng tÃ¬m tháº¥y response tá»« agent"
            
        except Exception as e:
            print(f"âŒ Chi tiáº¿t lá»—i: {e}")
            import traceback
            traceback.print_exc()
            return f"âŒ Lá»—i agent: {e}"